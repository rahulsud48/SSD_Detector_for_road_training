{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/.conda/envs/opcv/lib/python3.6/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib notebook\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from albumentations import (\n",
    "    CLAHE,\n",
    "    Blur,\n",
    "    OneOf,\n",
    "    Compose,\n",
    "    RGBShift,\n",
    "    GaussNoise,\n",
    "    RandomGamma,\n",
    "    RandomContrast,\n",
    "    RandomBrightness,\n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from albumentations.augmentations.transforms import HueSaturationValue\n",
    "from albumentations.augmentations.transforms import Normalize\n",
    "\n",
    "from trainer import Trainer, hooks, configuration\n",
    "from detector import Detector\n",
    "from trainer.utils import patch_configs\n",
    "from trainer.utils import setup_system\n",
    "from detection_loss import DetectionLoss\n",
    "from trainer.encoder import (\n",
    "    DataEncoder,\n",
    "    decode_boxes,\n",
    "    encode_boxes,\n",
    "    generate_anchors,\n",
    "    generate_anchor_grid,\n",
    ")\n",
    "from trainer.metrics import APEstimator\n",
    "from trainer.datasets import ListDataset\n",
    "# from trainer.data_set_downloader import DataSetDownloader \n",
    "from trainer.matplotlib_visualizer import MatplotlibVisualizer\n",
    "\n",
    "from typing import Callable, Iterable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SystemConfig:\n",
    "    seed: int = 42  # seed number to set the state of all random number generators\n",
    "    cudnn_benchmark_enabled: bool = False  # enable CuDNN benchmark for the sake of performance\n",
    "    cudnn_deterministic: bool = True  # make cudnn deterministic (reproducible training)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DatasetConfig:\n",
    "    root_dir: str = \"data\"  # dataset directory root\n",
    "    train_transforms: Iterable[Callable] = (\n",
    "        ToTensor(),\n",
    "    )  # data transformation to use during training data preparation\n",
    "    test_transforms: Iterable[Callable] = (\n",
    "        ToTensor(),\n",
    "    )  # data transformation to use during test data preparation\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataloaderConfig:\n",
    "    batch_size: int = 250  # amount of data to pass through the network at each forward-backward iteration\n",
    "    num_workers: int = 5  # number of concurrent processes using to prepare data\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OptimizerConfig:\n",
    "    learning_rate: float = 0.001  # determines the speed of network's weights update\n",
    "    momentum: float = 0.9  # used to improve vanilla SGD algorithm and provide better handling of local minimas\n",
    "    weight_decay: float = 0.0001  # amount of additional regularization on the weights values\n",
    "    lr_step_milestones: Iterable = (\n",
    "        30, 40\n",
    "    )  # at which epoches should we make a \"step\" in learning rate (i.e. decrease it in some manner)\n",
    "    lr_gamma: float = 0.1  # multiplier applied to current learning rate at each of lr_ctep_milestones\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainerConfig:\n",
    "    model_dir: str = \"checkpoints\"  # directory to save model states\n",
    "    model_save_best: bool = True  # save model with best accuracy\n",
    "    model_saving_frequency: int = 1  # frequency of model state savings per epochs\n",
    "    device: str = \"cpu\"  # device to use for training.\n",
    "    epoch_num: int = 50  # number of times the whole dataset will be passed through the network\n",
    "    progress_bar: bool = False  # enable progress bar visualization during train process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_configs(epoch_num_to_set=TrainerConfig.epoch_num, batch_size_to_set=DataloaderConfig.batch_size):\n",
    "    \"\"\" Patches configs if cuda is not available\n",
    "\n",
    "    Returns:\n",
    "        returns patched dataloader_config and trainer_config\n",
    "\n",
    "    \"\"\"\n",
    "    # default experiment params\n",
    "    num_workers_to_set = DataloaderConfig.num_workers\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        batch_size_to_set = 16\n",
    "        num_workers_to_set = 2\n",
    "        epoch_num_to_set = 1\n",
    "\n",
    "    dataloader_config = DataloaderConfig(batch_size=batch_size_to_set, num_workers=num_workers_to_set)\n",
    "    trainer_config = TrainerConfig(device=device, epoch_num=epoch_num_to_set, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5c329ee2d870>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataloader_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_num_to_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size_to_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m dataset_config = configuration.DatasetConfig(\n\u001b[1;32m      3\u001b[0m     \u001b[0mroot_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"../../../Datasets/Road_Scene_Object_Detection\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     train_transforms=[\n\u001b[1;32m      5\u001b[0m         \u001b[0mRandomBrightness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "dataloader_config, trainer_config = patch_configs(epoch_num_to_set=10, batch_size_to_set=1)\n",
    "dataset_config = configuration.DatasetConfig(\n",
    "    root_dir=\"../../../Datasets/Road_Scene_Object_Detection\",\n",
    "    train_transforms=[\n",
    "        RandomBrightness(p=0.5),\n",
    "        RandomContrast(p=0.5),\n",
    "        OneOf([\n",
    "            RandomGamma(),\n",
    "            HueSaturationValue(hue_shift_limit=20, sat_shift_limit=50, val_shift_limit=50),\n",
    "            RGBShift()\n",
    "        ],\n",
    "            p=1),\n",
    "        OneOf([Blur(always_apply=True), GaussNoise(always_apply=True)], p=1),\n",
    "        CLAHE(),\n",
    "        Normalize(),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_train = ListDataset(\n",
    "    root_dir=dataset_config.root_dir,\n",
    "    data_dir = 'export',\n",
    "    list_file='annots_converted_train.txt',\n",
    "\n",
    "    classes=[\n",
    "        \"__background__\",\n",
    "        \"biker\",\n",
    "        \"car\",\n",
    "        \"pedestrian\",\n",
    "        \"trafficLight\",\n",
    "        \"trafficLight-Green\",\n",
    "        \"trafficLight-GreenLeft\",\n",
    "        \"trafficLight-Red\",\n",
    "        \"trafficLight-RedLeft\",\n",
    "        \"trafficLight-Yellow\",\n",
    "        \"trafficLight-YellowLeft\",\n",
    "        \"truck\"\n",
    "    ],\n",
    "    mode='train',\n",
    "    transform=Compose(dataset_config.train_transforms),\n",
    "    input_size=300\n",
    ")\n",
    "\n",
    "loader_train = DataLoader(\n",
    "    dataset=dataset_train,\n",
    "    batch_size=dataloader_config.batch_size,\n",
    "    shuffle=True,\n",
    "#     collate_fn=dataset_train.collate_fn,\n",
    "    num_workers=dataloader_config.num_workers,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(loader_train)\n",
    "one_batch = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_batch = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 17451, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 17451])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_batch[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_batch[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
