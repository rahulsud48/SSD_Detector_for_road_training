{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from IPython.display import Code\n",
    "import inspect\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    resnet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_check = torch.from_numpy(np.random.random((2,3,256,256)))\n",
    "input_check = input_check.type(torch.FloatTensor)\n",
    "input_check = input_check.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_check = resnet(input_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000])\n"
     ]
    }
   ],
   "source": [
    "print(output_check.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = resnet.conv1(input_check)\n",
    "x = resnet.bn1(x)\n",
    "x = resnet.relu(x)\n",
    "x = resnet.maxpool(x)\n",
    "layer1_output = resnet.layer1(x)\n",
    "layer2_output = resnet.layer2(layer1_output)\n",
    "layer3_output = resnet.layer3(layer2_output)\n",
    "layer4_output = resnet.layer4(layer3_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1_output size: torch.Size([2, 64, 64, 64])\n",
      "layer2_output size: torch.Size([2, 128, 32, 32])\n",
      "layer3_output size: torch.Size([2, 256, 16, 16])\n",
      "layer4_output size: torch.Size([2, 512, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "print('layer1_output size: {}'.format(layer1_output.size()))\n",
    "print('layer2_output size: {}'.format(layer2_output.size()))\n",
    "print('layer3_output size: {}'.format(layer3_output.size()))\n",
    "print('layer4_output size: {}'.format(layer4_output.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPN(nn.Module):\n",
    "    def __init__(self, block_expansion=1, backbone=\"resnet18\"):\n",
    "        super().__init__()\n",
    "        assert hasattr(models, backbone), \"Undefined encoder type\"\n",
    "        \n",
    "        # load model \n",
    "        self.feature_extractor = getattr(models, backbone)(pretrained=True)\n",
    "        \n",
    "        # two more layers conv6 and conv7 on the top of layer4 (if backbone is resnet18)\n",
    "        \n",
    "        self.conv6 = nn.Conv2d(\n",
    "            512 * block_expansion, 64 * block_expansion, kernel_size=3, stride=2, padding=1\n",
    "        )\n",
    "        self.conv7 = nn.Conv2d(64 * block_expansion, 64 * block_expansion, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # lateral layers\n",
    "        \n",
    "        self.latlayer1 = nn.Conv2d(\n",
    "            512 * block_expansion, 64 * block_expansion, kernel_size=1, stride=1, padding=0\n",
    "        )\n",
    "        self.latlayer2 = nn.Conv2d(\n",
    "            256 * block_expansion, 64 * block_expansion, kernel_size=1, stride=1, padding=0\n",
    "        )\n",
    "        self.latlayer3 = nn.Conv2d(\n",
    "            128 * block_expansion, 64 * block_expansion, kernel_size=1, stride=1, padding=0\n",
    "        )\n",
    "\n",
    "        # top-down layers\n",
    "        self.toplayer1 = nn.Conv2d(\n",
    "            64 * block_expansion, 64 * block_expansion, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        self.toplayer2 = nn.Conv2d(\n",
    "            64 * block_expansion, 64 * block_expansion, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _upsample_add(x, y):\n",
    "        '''Upsample and add two feature maps.\n",
    "\n",
    "        Args:\n",
    "          x: (Variable) top feature map to be upsampled.\n",
    "          y: (Variable) lateral feature map.\n",
    "\n",
    "        Returns:\n",
    "          (Variable) added feature map.\n",
    "\n",
    "        Note in PyTorch, when input size is odd, the upsampled feature map\n",
    "        with `F.interpolate(..., scale_factor=2, mode='nearest')`\n",
    "        maybe not equal to the lateral feature map size.\n",
    "\n",
    "        e.g.\n",
    "        original input size: [N,_,15,15] ->\n",
    "        conv2d feature map size: [N,_,8,8] ->\n",
    "        upsampled feature map size: [N,_,16,16]\n",
    "\n",
    "        So we choose bilinear upsample which supports arbitrary output sizes.\n",
    "        '''\n",
    "        _, _, height, width = y.size()\n",
    "        return F.interpolate(x, size=(height, width), mode='bilinear', align_corners=True) + y\n",
    "\n",
    "    def forward(self, x):\n",
    "        # bottom-up\n",
    "        x = self.feature_extractor.conv1(x)\n",
    "        x = self.feature_extractor.bn1(x)\n",
    "        x = self.feature_extractor.relu(x)\n",
    "        x = self.feature_extractor.maxpool(x)\n",
    "        layer1_output = self.feature_extractor.layer1(x)\n",
    "        layer2_output = self.feature_extractor.layer2(layer1_output)\n",
    "        layer3_output = self.feature_extractor.layer3(layer2_output)\n",
    "        layer4_output = self.feature_extractor.layer4(layer3_output)\n",
    "\n",
    "        output = []\n",
    "        \n",
    "        # conv6 output. input is output of layer4\n",
    "        embedding = self.conv6(layer4_output)\n",
    "        \n",
    "        # conv7 output. input is relu activation of conv6 output\n",
    "        output.append(self.conv7(F.relu(embedding)))\n",
    "        output.append(embedding)\n",
    "        \n",
    "        # top-down\n",
    "        output.append(self.latlayer1(layer4_output))\n",
    "        output.append(self.toplayer1(self._upsample_add(output[-1], self.latlayer2(layer3_output))))\n",
    "        output.append(self.toplayer2(self._upsample_add(output[-1], self.latlayer3(layer2_output))))\n",
    "        \n",
    "        return output[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpn = FPN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPN(\n",
      "  (feature_extractor): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      "  )\n",
      "  (conv6): Conv2d(512, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (latlayer1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (latlayer2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (latlayer3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (toplayer1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (toplayer2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(fpn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 32, 32])\n",
      "torch.Size([2, 64, 16, 16])\n",
      "torch.Size([2, 64, 8, 8])\n",
      "torch.Size([2, 64, 4, 4])\n",
      "torch.Size([2, 64, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "input_check = input_check.to(\"cpu\")\n",
    "\n",
    "output = fpn(input_check)\n",
    "\n",
    "for layer in output:\n",
    "    print(layer.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 38, 38])\n",
      "torch.Size([2, 64, 19, 19])\n",
      "torch.Size([2, 64, 10, 10])\n",
      "torch.Size([2, 64, 5, 5])\n",
      "torch.Size([2, 64, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "image_inputs = torch.rand((2, 3, 300, 300))\n",
    "\n",
    "output = fpn(image_inputs)\n",
    "\n",
    "for layer in output:\n",
    "    print(layer.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector(nn.Module):\n",
    "    num_anchors = 9\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(Detector, self).__init__()\n",
    "        self.fpn = FPN()\n",
    "        self.num_classes = num_classes\n",
    "        self.loc_head = self._make_head(self.num_anchors * 4)\n",
    "        self.cls_head = self._make_head(self.num_anchors * self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        fms = self.fpn(x)\n",
    "        loc_preds = []\n",
    "        cls_preds = []\n",
    "        for feature_map in fms:\n",
    "            loc_pred = self.loc_head(feature_map)\n",
    "            cls_pred = self.cls_head(feature_map)\n",
    "            loc_pred = loc_pred.permute(0, 2, 3, 1).contiguous().view(\n",
    "                x.size(0), -1, 4\n",
    "            )  # [N, 9*4,H,W] -> [N,H,W, 9*4] -> [N,H*W*9, 4]\n",
    "            cls_pred = cls_pred.permute(0, 2, 3, 1).contiguous().view(\n",
    "                x.size(0), -1, self.num_classes\n",
    "            )  # [N,9*20,H,W] -> [N,H,W,9*20] -> [N,H*W*9,20]\n",
    "            loc_preds.append(loc_pred)\n",
    "            cls_preds.append(cls_pred)\n",
    "            \n",
    "        \n",
    "        return torch.cat(loc_preds, 1), torch.cat(cls_preds, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_head(out_planes):\n",
    "        layers = []\n",
    "        for _ in range(4):\n",
    "            layers.append(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1))\n",
    "            layers.append(nn.ReLU(True))\n",
    "        layers.append(nn.Conv2d(64, out_planes, kernel_size=3, stride=1, padding=1))\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location_pred size: torch.Size([2, 12276, 4])\n",
      "class_pred size: torch.Size([2, 12276, 2])\n"
     ]
    }
   ],
   "source": [
    "image_inputs = torch.rand((2, 3, 256, 256))\n",
    "\n",
    "detector = Detector()\n",
    "\n",
    "location_pred, class_pred = detector(image_inputs)\n",
    "\n",
    "print('location_pred size: {}'.format(location_pred.size()))\n",
    "\n",
    "print('class_pred size: {}'.format(class_pred.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location_pred size: torch.Size([2, 17451, 4])\n",
      "class_pred size: torch.Size([2, 17451, 2])\n"
     ]
    }
   ],
   "source": [
    "image_inputs = torch.rand((2, 3, 300, 300))\n",
    "\n",
    "location_pred, class_pred = detector(image_inputs)\n",
    "\n",
    "print('location_pred size: {}'.format(location_pred.size()))\n",
    "\n",
    "print('class_pred size: {}'.format(class_pred.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
